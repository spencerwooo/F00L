{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison among five different attack algorithms\n",
    "\n",
    "**Attack**\n",
    "\n",
    "- Attack algorithms: 'FGSM', 'DeepFool', 'JSMA', 'CW', 'MI-FGSM'\n",
    "- Target: pretrained ResNet18 model with ImageNet weights targeted on ImageNette, a subset of ImageNet:\n",
    "- Parameters to compare: attack effectiveness, adversarial generation time\n",
    "\n",
    "**Image Scaling**\n",
    "\n",
    "- Scaling library: OpenCV\n",
    "- Scaling factors: ×2, ×0.5\n",
    "- Scaling interpolations: \n",
    "\n",
    "    ```\n",
    "    {\n",
    "      'INTER_NEAREST': cv2.INTER_NEAREST,\n",
    "      'INTER_LINEAR': cv2.INTER_LINEAR,\n",
    "      'INTER_AREA': cv2.INTER_AREA,\n",
    "      'INTER_CUBIC': cv2.INTER_CUBIC,\n",
    "      'INTER_LANCZOS4': cv2.INTER_LANCZOS4\n",
    "    }\n",
    "    ```\n",
    "\n",
    "Model weights: https://drive.google.com/open?id=1_7zra0xWcHnub4Cz6ryBJXjohgRNmA0f\n",
    "\n",
    "ImageNette: https://github.com/fastai/imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import foolbox\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "# pretrained model state_dict path\n",
    "MODEL_PATH = '200228_1003_inception_v3_imagenette.pth'\n",
    "\n",
    "# 10 classes\n",
    "CLASS_NAMES = [\n",
    "    'tench', 'English springer', 'cassette player', 'chain saw', 'church', 'French horn', 'garbage truck', 'gas pump',\n",
    "    'golf ball', 'parachute'\n",
    "]\n",
    "\n",
    "# instantiate model\n",
    "model = torchvision.models.inception_v3(pretrained=True, aux_logits=False)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(CLASS_NAMES))\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "print('Instantiated ConvNET model: InceptionV3ImageNette.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  model = model.cuda()\n",
    "\n",
    "# instantiate Foolbox wrapper\n",
    "preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "\n",
    "fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1), num_classes=10, preprocessing=preprocessing)\n",
    "\n",
    "# load validation images\n",
    "transform = transforms.Compose([transforms.Resize((213, 213)), transforms.ToTensor()])\n",
    "\n",
    "dataset_path = '../data/imagenette2-160/val'\n",
    "dataset = torchvision.datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# indice at which each class starts: [0, 200, 400 ... 1800]\n",
    "class_start_indice = [indice * 200 for indice in range(0, 10)]\n",
    "# grab 10 images from each class: [0, 1, 2 ... 9, 200, 201, 202 ... 1800, 1801, 1802 ... 1809]\n",
    "images_in_class_indice = np.array([[j for j in range(k, k + 10)] for k in class_start_indice]).flatten()\n",
    "\n",
    "# size of each batch\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# get 10 images from 10 classes for a total of 100 images\n",
    "dataset = torch.utils.data.Subset(dataset, images_in_class_indice)\n",
    "# compose dataset into dataloader\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "print('Loaded data from: {} with a total of {} images.'.format(dataset_path, dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate model's base prediction accuracy (about 97%)\n",
    "# takes about 5 seconds on GPU\n",
    "pbar = tqdm(dataset_loader)\n",
    "pbar.set_description('Validate predictions')\n",
    "pbar.set_postfix(acc='0.0%')\n",
    "\n",
    "preds = []\n",
    "acc = 0.0\n",
    "for i, (image, label) in enumerate(pbar):\n",
    "  # make a prediction\n",
    "  prob = fmodel.forward(image.numpy())\n",
    "  pred = np.argmax(prob, axis=-1)\n",
    "  preds.append(pred)\n",
    "\n",
    "  # calculate current accuracy\n",
    "  acc += np.sum(pred == label.numpy())\n",
    "  current_acc = acc * 100 / ((i + 1) * BATCH_SIZE)\n",
    "  pbar.set_postfix(acc='{:.2f}%'.format(current_acc))\n",
    "\n",
    "acc = acc * 100 / dataset_size\n",
    "# pbar.write('\\nValidated with accuracy of: {:.2f}%'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform multiple attacks with different algorithms\n",
    "#\n",
    "# - FGSM: takes about 30s on GPU with attack effectiveness of 82%\n",
    "# - DeepFool: takes about 3m on GPU with attack effectiveness of 93%\n",
    "# - JSMA: takes about 49m on GPU\n",
    "# - CW: takes about 3 hours on GPU\n",
    "# - MI-FGSM: takes about 30m on GPU with attack effectiveness of 100%\n",
    "\n",
    "means_of_attack = ['FGSM', 'DeepFool', 'JSMA', 'CW', 'MI-FGSM']\n",
    "# means_of_attack = ['FGSM', 'DeepFool']\n",
    "\n",
    "\n",
    "def attack_switcher(att):\n",
    "  switcher = {\n",
    "      'FGSM': foolbox.attacks.GradientSignAttack(fmodel, distance=foolbox.distances.Linf),\n",
    "      'DeepFool': foolbox.attacks.DeepFoolAttack(fmodel, distance=foolbox.distances.Linf),\n",
    "      'JSMA': foolbox.attacks.SaliencyMapAttack(fmodel, distance=foolbox.distances.Linf),\n",
    "      'CW': foolbox.attacks.CarliniWagnerL2Attack(fmodel, distance=foolbox.distances.Linf),\n",
    "      'MI-FGSM': foolbox.attacks.MomentumIterativeAttack(fmodel, distance=foolbox.distances.Linf)\n",
    "  }\n",
    "  return switcher.get(att)\n",
    "\n",
    "\n",
    "# time (secs) used to generate adversarials, key: attack method\n",
    "time_elapsed_dict = {att: None for att in means_of_attack}\n",
    "# generated adversarials, key: attack method\n",
    "adversarials_dict = {att: [] for att in means_of_attack}\n",
    "\n",
    "for attack_method in means_of_attack:\n",
    "  tic = time.time()\n",
    "  attack = attack_switcher(attack_method)\n",
    "\n",
    "  pbar = tqdm(dataset_loader)\n",
    "  pbar.set_description('Attacking with {:>8}'.format(attack_method))\n",
    "\n",
    "  adversarials = []\n",
    "\n",
    "  # iterate through images to generate adversarials\n",
    "  for image, label in pbar:\n",
    "\n",
    "    if attack_method == 'FGSM':\n",
    "      # FGSM: issues an `epsilon` parameter\n",
    "      eps = [0.01 * i for i in range(0, 10)]\n",
    "      adv = attack(image.numpy(), label.numpy(), epsilons=eps)\n",
    "    elif attack_method == 'DeepFool':\n",
    "      # DeepFool: steps 5, subsample of 5 classes\n",
    "      adv = attack(image.numpy(), label.numpy(), steps=5, subsample=5)\n",
    "    elif attack_method == 'JSMA':\n",
    "      # Saliency Map Attack\n",
    "      adv = attack(image.numpy(), label.numpy(), max_iter=1000)\n",
    "    elif attack_method == 'CW':\n",
    "      # L2 version of the Carlini & Wagner attack\n",
    "      adv = attack(image.numpy(), label.numpy(), max_iterations=500)\n",
    "    elif attack_method == 'MI-FGSM':\n",
    "      # The Momentum Iterative Method attack\n",
    "      adv = attack(image.numpy(), label.numpy(), epsilon=0.1, stepsize=0.01)\n",
    "    else:\n",
    "      raise Exception('Attack method not found.')\n",
    "\n",
    "    # if an attack fails under preferred criterions, `np.nan` is returned,\n",
    "    #  in which case, we'll return the original image\n",
    "    for i, (single_adv, single_image) in enumerate(zip(adv, image.numpy())):\n",
    "      if np.isnan(single_adv).any():\n",
    "        adv[i] = single_image\n",
    "\n",
    "    adversarials.append(adv)\n",
    "\n",
    "  toc = time.time()\n",
    "  time_elapsed = toc - tic\n",
    "  # pbar.write(' Time: {}m{:.2f}s'.format(\n",
    "  #     time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "  # collect statistics\n",
    "  adversarials_dict[attack_method] = adversarials\n",
    "  time_elapsed_dict[attack_method] = time_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize adversarials\n",
    "\n",
    "# resize scale: [0.5, 2]\n",
    "resize_scale = 2\n",
    "# interpolation methods\n",
    "interpolation_method_name = 'INTER_LANCZOS4'\n",
    "interpolation_methods = {\n",
    "    'INTER_NEAREST': cv2.INTER_NEAREST,\n",
    "    'INTER_LINEAR': cv2.INTER_LINEAR,\n",
    "    'INTER_AREA': cv2.INTER_AREA,\n",
    "    'INTER_CUBIC': cv2.INTER_CUBIC,\n",
    "    'INTER_LANCZOS4': cv2.INTER_LANCZOS4\n",
    "}\n",
    "interpolation = interpolation_methods[interpolation_method_name]\n",
    "resized_adversarials_dict = {attack_method: [] for attack_method in means_of_attack}\n",
    "\n",
    "for attack_method in means_of_attack:\n",
    "  for adv_batch in adversarials_dict[attack_method]:\n",
    "    resized_adv_batch = []\n",
    "    for adv in adv_batch:\n",
    "      # opencv take images as channels last (213, 213, 3)\n",
    "      # while our model treats images as channels first (3, 213, 213)\n",
    "      resized_adv = cv2.resize(np.moveaxis(adv, 0, 2), (0, 0),\n",
    "                               fx=resize_scale,\n",
    "                               fy=resize_scale,\n",
    "                               interpolation=interpolation)\n",
    "      resized_adv_batch.append(np.moveaxis(resized_adv, 2, 0))\n",
    "    resized_adversarials_dict[attack_method].append(np.array(resized_adv_batch))\n",
    "\n",
    "print('Done! Resized adversarials using {} with a scale of {}.'.format(interpolation_method_name, resize_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate generated adversarial examples\n",
    "validate_control_group = True\n",
    "\n",
    "# Validation adversarial set\n",
    "validation_adv_set = None\n",
    "# - control group: `adversarials_dict`\n",
    "# - downscale x0.5: `resized_adversarials_dict`\n",
    "if validate_control_group:\n",
    "  validation_adv_set = adversarials_dict\n",
    "else:\n",
    "  validation_adv_set = resized_adversarials_dict\n",
    "\n",
    "# effectiveness of each attack method\n",
    "attack_acc_dict = {att: None for att in means_of_attack}\n",
    "\n",
    "for attack_method in means_of_attack:\n",
    "  adv_acc = 0.0\n",
    "  adv_preds = []\n",
    "  adv_failed = []\n",
    "  pbar = tqdm(dataset_loader)\n",
    "  pbar.set_description('Validate {:>8}'.format(attack_method))\n",
    "  pbar.set_postfix(acc='0.00%')\n",
    "  adversarials = validation_adv_set[attack_method]\n",
    "\n",
    "  for i, (_, label) in enumerate(pbar):\n",
    "    adv_prob = fmodel.forward(adversarials[i])\n",
    "    adv_pred = np.argmax(adv_prob, axis=-1)\n",
    "    adv_preds.append(adv_pred)\n",
    "\n",
    "    # collect index of the image at which the\n",
    "    # attack failed (adversarial == ground truth)\n",
    "    for j, (single_adv_pred, single_label) in enumerate(zip(adv_pred, label.numpy())):\n",
    "      if single_adv_pred == single_label:\n",
    "        adv_failed.append(i + j)\n",
    "\n",
    "    adv_acc += np.sum(adv_pred == label.numpy())\n",
    "    cur_adv_acc = adv_acc * 100 / ((i + 1) * BATCH_SIZE)\n",
    "    pbar.set_postfix(acc='{:.2f}%'.format(cur_adv_acc))\n",
    "\n",
    "  # accuracy of which the model predicts adversarial examples (percentage)\n",
    "  adv_acc = adv_acc * 100 / dataset_size\n",
    "  # 100 - accuracy = effectiveness of said attack (percentage)\n",
    "  attack_acc_dict[attack_method] = 100 - adv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print statistics\n",
    "# image manipulation: control_group, interpolation methods x 5, scale = [0.5, 2]\n",
    "manipulation_method = 'Control group' if validate_control_group == True else \\\n",
    "                      'Interpolation: {}, scale: x{}'.format(interpolation_method_name,\n",
    "                                                                resize_scale)\n",
    "\n",
    "print(manipulation_method)\n",
    "for attack_method in means_of_attack:\n",
    "  print('{:>8} | success rate: {:>5.1f}% | time cost: {:>6.2f}s'.format(attack_method, attack_acc_dict[attack_method],\n",
    "                                                                        time_elapsed_dict[attack_method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get longest duration for attack to complete\n",
    "longest_time_used = 0\n",
    "for key in time_elapsed_dict:\n",
    "  if time_elapsed_dict[key] > longest_time_used:\n",
    "    longest_time_used = time_elapsed_dict[key]\n",
    "\n",
    "# Plot statistics\n",
    "x_labels = [method for method in means_of_attack]\n",
    "x = np.arange(len(x_labels))\n",
    "width = 0.2\n",
    "fig, ax1 = plt.subplots(sharey=False)\n",
    "rect_acc = ax1.bar(x - width / 2 - 0.02, [attack_acc_dict[key] for key in attack_acc_dict],\n",
    "                   width,\n",
    "                   label='Attack effectiveness',\n",
    "                   color='#e4508f')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(x_labels)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.set_ylabel('Attack effectiveness (%)', color='#e4508f')\n",
    "ax1.tick_params(axis='y', labelcolor='#e4508f')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "rect_time = ax2.bar(x + width / 2 + 0.02, [time_elapsed_dict[key] for key in time_elapsed_dict],\n",
    "                    width,\n",
    "                    label='Cost of time',\n",
    "                    color='#556fb5')\n",
    "ax2.set_ylim(0, longest_time_used * 1.2)\n",
    "ax2.set_ylabel('Attack time cost (s)', color='#556fb5')\n",
    "ax2.tick_params(axis='y', labelcolor='#556fb5')\n",
    "\n",
    "\n",
    "def auto_label(ax, rects, unit=None):\n",
    "  for rect in rects:\n",
    "    height = rect.get_height()\n",
    "    ax.annotate('{:.1f}{}'.format(height, unit),\n",
    "                xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center',\n",
    "                va='bottom')\n",
    "\n",
    "\n",
    "auto_label(ax1, rect_acc, unit='%')\n",
    "auto_label(ax2, rect_time, unit='s')\n",
    "plt.title(manipulation_method)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
