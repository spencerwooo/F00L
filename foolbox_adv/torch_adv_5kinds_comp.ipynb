{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","\n","import foolbox\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","\n","import cv2\n","\n","# pretrained model state_dict path\n","MODEL_PATH = 'resnet_imagenette.pth'\n","\n","# 10 classes\n","CLASS_NAMES = ['tench', 'English springer', 'cassette player', 'chain saw', 'church',\n","               'French horn', 'garbage truck', 'gas pump', 'golf ball', 'parachute']\n","\n","# instantiate model\n","model = torchvision.models.resnet18(pretrained=True)\n","\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, len(CLASS_NAMES))\n","\n","model.load_state_dict(torch.load(MODEL_PATH))\n","model.eval()\n","\n","print('Instantiated ConvNET model: ResNet18ImageNette.')\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# use GPU if available\n","if torch.cuda.is_available():\n","  model = model.cuda()\n","\n","# instantiate Foolbox wrapper\n","preprocessing = dict(mean=[0.485, 0.456, 0.406],\n","                     std=[0.229, 0.224, 0.225], axis=-3)\n","\n","fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1),\n","                                     num_classes=10,\n","                                     preprocessing=preprocessing)\n","\n","# load validation images\n","transform = transforms.Compose([\n","    transforms.Resize((213, 213)),\n","    transforms.ToTensor()\n","])\n","\n","dataset_path = '../data/imagenette2-160/val'\n","dataset = torchvision.datasets.ImageFolder(\n","    root=dataset_path, transform=transform)\n","\n","# indice at which each class starts: [0, 200, 400 ... 1800]\n","class_start_indice = [indice * 200 for indice in range(0, 10)]\n","# grab 10 images from each class: [0, 1, 2 ... 9, 200, 201, 202 ... 1800, 1801, 1802 ... 1809]\n","images_in_class_indice = np.array(\n","    [[j for j in range(k, k + 10)] for k in class_start_indice]).flatten()\n","\n","# size of each batch\n","BATCH_SIZE = 4\n","\n","# get 10 images from 10 classes for a total of 100 images\n","dataset = torch.utils.data.Subset(dataset, images_in_class_indice)\n","# compose dataset into dataloader\n","dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n","dataset_size = len(dataset)\n","\n","print('Loaded data from: {} with a total of {} images.'.format(\n","    dataset_path, dataset_size))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Validate model's base prediction accuracy (about 97%)\n","# takes about 5 seconds on GPU\n","pbar = tqdm(dataset_loader)\n","pbar.set_description('Validate predictions')\n","pbar.set_postfix(acc='0.0%')\n","\n","preds = []\n","acc = 0.0\n","for i, (image, label) in enumerate(pbar):\n","  # make a prediction\n","  prob = fmodel.forward(image.numpy())\n","  pred = np.argmax(prob, axis=-1)\n","  preds.append(pred)\n","\n","  # calculate current accuracy\n","  acc += np.sum(pred == label.numpy())\n","  current_acc = acc * 100 / ((i + 1) * BATCH_SIZE)\n","  pbar.set_postfix(acc='{:.2f}%'.format(current_acc))\n","\n","acc = acc * 100 / dataset_size\n","pbar.write('\\nValidated with accuracy of: {:.2f}%'.format(acc))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Perform multiple attacks with different algorithms\n","#\n","# - FGSM: takes about 30s on GPU with attack effectiveness of 82%\n","# - DeepFool: takes about 3m on GPU with attack effectiveness of 93%\n","# - JSMA: takes about 49m on GPU\n","# - CW: takes about 3 hours on GPU\n","# - MI-FGSM: takes about 30m on GPU with attack effectiveness of 100%\n","\n","# means_of_attack = ['FGSM', 'DeepFool', 'JSMA', 'CW', 'MI-FGSM']\n","means_of_attack = ['FGSM']\n","\n","\n","def attack_switcher(att):\n","  switcher = {\n","      'FGSM': foolbox.attacks.GradientSignAttack(fmodel),\n","      'DeepFool': foolbox.attacks.DeepFoolAttack(fmodel),\n","      'JSMA': foolbox.attacks.SaliencyMapAttack(fmodel),\n","      'CW': foolbox.attacks.CarliniWagnerL2Attack(fmodel),\n","      'MI-FGSM': foolbox.attacks.MomentumIterativeAttack(fmodel, distance=foolbox.distances.Linf)\n","  }\n","  return switcher.get(att)\n","\n","\n","# time (secs) used to generate adversarials, key: attack method\n","time_elapsed_dict = {att: None for att in means_of_attack}\n","# generated adversarials, key: attack method\n","adversarials_dict = {att: [] for att in means_of_attack}\n","\n","for attack_method in means_of_attack:\n","  tic = time.time()\n","  attack = attack_switcher(attack_method)\n","\n","  pbar = tqdm(dataset_loader)\n","  pbar.set_description('Attacking with {:>8}'.format(attack_method))\n","\n","  adversarials = []\n","\n","  # iterate through images to generate adversarials\n","  for image, label in pbar:\n","\n","    if attack_method == 'FGSM':\n","      # FGSM: issues an `epsilon` parameter\n","      eps = [0.01 * i for i in range(0, 10)]\n","      adv = attack(image.numpy(), label.numpy(), epsilons=eps)\n","    elif attack_method == 'DeepFool':\n","      # DeepFool: steps 5, subsample of 5 classes\n","      adv = attack(image.numpy(), label.numpy(), steps=5, subsample=5)\n","    elif attack_method == 'JSMA':\n","      # Saliency Map Attack\n","      adv = attack(image.numpy(), label.numpy(), max_iter=1000)\n","    elif attack_method == 'CW':\n","      # L2 version of the Carlini & Wagner attack\n","      adv = attack(image.numpy(), label.numpy())\n","    elif attack_method == 'MI-FGSM':\n","      # The Momentum Iterative Method attack\n","      adv = attack(image.numpy(), label.numpy())\n","    else:\n","      raise Exception('Attack method not found.')\n","\n","    # if an attack fails under preferred criterions, `np.nan` is returned,\n","    #  in which case, we'll return the original image\n","    for i, (single_adv, single_image) in enumerate(zip(adv, image.numpy())):\n","      if np.isnan(single_adv).any():\n","        adv[i] = single_image\n","\n","    adversarials.append(adv)\n","\n","  toc = time.time()\n","  time_elapsed = toc - tic\n","  # pbar.write(' Time: {}m{:.2f}s'.format(\n","  #     time_elapsed // 60, time_elapsed % 60))\n","\n","  # collect statistics\n","  adversarials_dict[attack_method] = adversarials\n","  time_elapsed_dict[attack_method] = time_elapsed\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# resize adversarials\n","resize_scale = 0.5\n","interpolation = cv2.INTER_LINEAR\n","resized_adversarials_dict = {attack_method: []\n","                             for attack_method in means_of_attack}\n","\n","for attack_method in means_of_attack:\n","  for adv_batch in adversarials_dict[attack_method]:\n","    resized_adv_batch = []\n","    for adv in adv_batch:\n","      # opencv take images as channels last (213, 213, 3)\n","      # while our model treats images as channels first (3, 213, 213)\n","      resized_adv = cv2.resize(np.moveaxis(adv, 0, 2), (0, 0),\n","                               fx=resize_scale, fy=resize_scale,\n","                               interpolation=interpolation)\n","      resized_adv_batch.append(np.moveaxis(resized_adv, 2, 0))\n","    resized_adversarials_dict[attack_method].append(\n","        np.array(resized_adv_batch))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Validate generated adversarial examples\n","\n","# Validation adversarial set:\n","# - control group: `adversarials_dict`\n","# - downscale x0.5: `resized_adversarials_dict`\n","validation_adv_set = resized_adversarials_dict\n","\n","# effectiveness of each attack method\n","attack_acc_dict = {att: None for att in means_of_attack}\n","\n","for attack_method in means_of_attack:\n","  adv_acc = 0.0\n","  adv_preds = []\n","  adv_failed = []\n","  pbar = tqdm(dataset_loader)\n","  pbar.set_description('Validate {:>8}'.format(attack_method))\n","  pbar.set_postfix(acc='0.00%')\n","  adversarials = validation_adv_set[attack_method]\n","\n","  for i, (_, label) in enumerate(pbar):\n","    adv_prob = fmodel.forward(adversarials[i])\n","    adv_pred = np.argmax(adv_prob, axis=-1)\n","    adv_preds.append(adv_pred)\n","\n","    # collect index of the image at which the\n","    # attack failed (adversarial == ground truth)\n","    for j, (single_adv_pred, single_label) in enumerate(zip(adv_pred, label.numpy())):\n","      if single_adv_pred == single_label:\n","        adv_failed.append(i + j)\n","\n","    adv_acc += np.sum(adv_pred == label.numpy())\n","    cur_adv_acc = adv_acc * 100 / ((i + 1) * BATCH_SIZE)\n","    pbar.set_postfix(acc='{:.2f}%'.format(cur_adv_acc))\n","\n","  # accuracy of which the model predicts adversarial examples (percentage)\n","  adv_acc = adv_acc * 100 / dataset_size\n","  # 100 - accuracy = effectiveness of said attack (percentage)\n","  attack_acc_dict[attack_method] = 100 - adv_acc\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get longest duration for attack to complete\n","longest_time_used = 0\n","for key in time_elapsed_dict:\n","  if time_elapsed_dict[key] > longest_time_used:\n","    longest_time_used = time_elapsed_dict[key]\n","\n","# Plot statistics\n","x_labels = [method for method in means_of_attack]\n","x = np.arange(len(x_labels))\n","width = 0.2\n","fig, ax1 = plt.subplots(sharey=False)\n","rect_acc = ax1.bar(x - width / 2 - 0.02,\n","                   [attack_acc_dict[key] for key in attack_acc_dict],\n","                   width, label='Attack effectiveness', color='#e4508f')\n","ax1.set_xticks(x)\n","ax1.set_xticklabels(x_labels)\n","ax1.set_ylim(0, longest_time_used)\n","ax1.set_ylabel('Attack effectiveness (%)', color='#e4508f')\n","ax1.tick_params(axis='y', labelcolor='#e4508f')\n","\n","ax2 = ax1.twinx()\n","rect_time = ax2.bar(x + width / 2 + 0.02,\n","                    [time_elapsed_dict[key] for key in time_elapsed_dict],\n","                    width, label='Cost of time', color='#556fb5')\n","ax2.set_ylim(0, 3000)\n","ax2.set_ylabel('Attack time cost (s)', color='#556fb5')\n","ax2.tick_params(axis='y', labelcolor='#556fb5')\n","\n","\n","def auto_label(ax, rects, unit=None):\n","  for rect in rects:\n","    height = rect.get_height()\n","    ax.annotate('{:.1f}{}'.format(height, unit),\n","                xy=(rect.get_x() + rect.get_width() / 2, height),\n","                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n","\n","\n","auto_label(ax1, rect_acc, unit='%')\n","auto_label(ax2, rect_time, unit='s')\n","\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}